{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dfb1478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Bashar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Bashar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import dask.dataframe as ddf\n",
    "\n",
    "from notnews import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940c9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(s, n):\n",
    "    pieces = str(s).split()\n",
    "    return (' '.join(pieces[i:i+n]) for i in range(0, len(pieces), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5327a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, column, num=500):\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        w_generator = split_text(presplit, num)\n",
    "        for word in w_generator:\n",
    "            indexes.append(i)\n",
    "            new_values.append(word)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af26d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn-1.csv\n",
      "Processing: cnn-1.csv ....\n",
      "Finished splitting cnn-1.csv into chunks\n",
      "Using model data from /Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/notnews/data/us_model/nyt_us_soft_news_classifier.joblib...\n",
      "Using vectorizer data from /Users/Bashar/opt/anaconda3/envs/nonconform/lib/python3.8/site-packages/notnews/data/us_model/nyt_us_soft_news_vectorizer.joblib...\n",
      "Loading the model and vectorizer data file...\n",
      "Saving results for cnn-1.csv\n",
      "\n",
      "\n",
      "cnn-2.csv\n",
      "Processing: cnn-2.csv ....\n",
      "Finished splitting cnn-2.csv into chunks\n"
     ]
    }
   ],
   "source": [
    "big_dd = pd.DataFrame()\n",
    "for file in os.listdir('../dataverse_files/'):\n",
    "    if file.endswith(\".csv\"):\n",
    "        print (file)\n",
    "        dd = pd.read_csv('../dataverse_files/'+ str(file), encoding = 'ISO-8859-1')\n",
    "        print (f'Processing: {file} ....')\n",
    "        split_dd = split_df(dd, 'text')\n",
    "        print (f'Finished splitting {file} into chunks')\n",
    "        soft_news_df = pred_soft_news_us(split_dd, col='text')\n",
    "        print (f'Saving results for {file}\\n\\n')\n",
    "        soft_news_df.to_csv(f'../dataverse_files/soft_news_{file}')\n",
    "        big_dd = pd.concat([big_dd,soft_news_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba29bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
