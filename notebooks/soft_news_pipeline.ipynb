{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c2f396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Bashar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Bashar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from notnews import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cda36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '../dataverse_files/'\n",
    "PROCESSED_PATH = FILE_PATH + 'processed/'\n",
    "PREDICT_NEWS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc76b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(s, n):\n",
    "    pieces = str(s).split()\n",
    "    return (' '.join(pieces[i:i+n]) for i in range(0, len(pieces), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd6de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, column, num=500):\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        w_generator = split_text(presplit, num)\n",
    "        for word in w_generator:\n",
    "            indexes.append(i)\n",
    "            new_values.append(word)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85029408",
   "metadata": {},
   "source": [
    "# Predicting Soft News probability\n",
    "If PREDICT_NEWS = True then will run, this is very time consuming and should be run once\n",
    "After which, the files generated should be saved to disk and preserved for future analysis\n",
    "  as run time could take days depending on the number of records to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe02098",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (PREDICT_NEWS):\n",
    "    for file in os.listdir('../dataverse_files/'):\n",
    "        if file.endswith(\".csv\"):\n",
    "            print (file)\n",
    "            dd = pd.read_csv( FILE_PATH + str(file), encoding = 'ISO-8859-1')\n",
    "            print (f'Processing: {FILE_PATH + str(file)} ....')\n",
    "            split_dd = split_df(dd, 'text')\n",
    "            print (f'Finished splitting {FILE_PATH + str(file)} into chunks')\n",
    "            soft_news_df = pred_soft_news_us(split_dd, col='text')\n",
    "            print (f'Saving results for {FILE_PATH + str(file)}\\n\\n')\n",
    "            soft_news_df.to_csv('{}soft_news_{}'.format(PROCESSED_PATH, file))\n",
    "            os.rename(FILE_PATH+file, PROCESSED_PATH+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325cb6c",
   "metadata": {},
   "source": [
    "# Processing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12519a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e6e544",
   "metadata": {},
   "source": [
    "## Processing CNN Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing CNN files\n",
    "processed_files = glob.glob(PROCESSED_PATH + 'soft_news_cnn*.csv')\n",
    "\n",
    "\n",
    "for file in processed_files:\n",
    "    news_df = pd.read_csv(file, encoding = 'ISO-8859-1')\n",
    "\n",
    "    # Default to CNN and then get the index prior to splitting into mulit-records and assign all records\n",
    "    #  to CNN International if the transcript contains CNN International in its text.\n",
    "    news_df['channel.name'] = 'CNN'\n",
    "    mod_list = news_df.loc[news_df['text'].str.contains('CNN INTERNATIONAL', case=False)]['Unnamed: 0'].tolist()    \n",
    "    news_df.iloc[mod_list,2] = 'CNN International'\n",
    "    \n",
    "    # delete any outliers\n",
    "    news_df.drop(news_df[news_df['year'] > 2100.0].index , axis=0, inplace=True)\n",
    "    news_df.drop(news_df[news_df['year'] < 1900.0].index , axis=0, inplace=True)    \n",
    "\n",
    "    # generate date field in format YYYY-MM-DD\n",
    "    news_df['full_date'] = pd.to_datetime((news_df.year*10000+news_df.month*100+news_df.date),format='%Y%m%d')\n",
    "    \n",
    "    # cleaning up the dataframe and appending to the full dataframe\n",
    "    news_df = news_df[news_df.columns[news_df.columns.isin(['channel.name','program.name','full_date','prob_soft_news_us'])]]\n",
    "    full_df = pd.concat([full_df, news_df], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b82808",
   "metadata": {},
   "outputs": [],
   "source": [
    "del news_df\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630622f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33e1fd",
   "metadata": {},
   "source": [
    "## Processing NBC/MSNBC files\n",
    "these files have different formats so we'll need to process individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f6d3e2",
   "metadata": {},
   "source": [
    "### MSNBC 2003-2014 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5487f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('../dataverse_files/processed/soft_news_msnbc--2003--2014.csv')\n",
    "news_df.rename(columns={'Source':'channel.name', 'Show':'program.name'},inplace=True)\n",
    "news_df['full_date'] = pd.to_datetime(news_df.Date)\n",
    "\n",
    "# keeping only the required columns in the dataframe\n",
    "news_df = news_df[news_df.columns[news_df.columns.isin(['channel.name','program.name','full_date','prob_soft_news_us'])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7412c",
   "metadata": {},
   "source": [
    "### MSNBC 2010-2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "news2_df = pd.read_csv('../dataverse_files/processed/soft_news_msnbc-2010--2021.csv')\n",
    "news2_df.drop('program.name', axis=1, inplace=True)\n",
    "news2_df.rename(columns={'Source':'channel.name', 'show_name':'program.name'},inplace=True)\n",
    "news2_df['full_date'] = pd.to_datetime(news2_df.air_date)\n",
    "\n",
    "# keeping only the required columns in the dataframe\n",
    "news2_df = news2_df[news2_df.columns[news2_df.columns.isin(['channel.name','program.name','full_date','prob_soft_news_us'])]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Size of 2003-2014 df: {news_df.shape}')\n",
    "print (f'Size of 2010-2021 df: {news2_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4ca7b",
   "metadata": {},
   "source": [
    "Merging the 2 dataframes to see if there is any redundant records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.merge(news2_df, how='outer', on=['channel.name','program.name','full_date', 'prob_soft_news_us'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d318a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([full_df, news_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbdb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "del news2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dda19d",
   "metadata": {},
   "source": [
    "### Processing NBC News data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('../dataverse_files/processed/soft_news_msnbc.csv', encoding = 'ISO-8859-1')\n",
    "news_df['channel.name'] = 'NBC News'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c332454",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.drop(news_df[news_df['date'].isnull()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df.drop(news_df[news_df['year'] > 2100.0].index , axis=0)\n",
    "news_df = news_df.drop(news_df[news_df['year'] < 1900.0].index , axis=0)    \n",
    "\n",
    "news_df['full_date'] = pd.to_datetime((news_df.year*10000+news_df.month*100+news_df.date),format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only the required columns in the dataframe\n",
    "news_df = news_df[news_df.columns[news_df.columns.isin(['channel.name','program.name','full_date','prob_soft_news_us'])]]\n",
    "\n",
    "full_df = pd.concat([full_df, news_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff537d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.drop(full_df[full_df['program.name'].isnull()].index, axis=0, inplace=True)\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7166e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1e5a3",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_shows(df):\n",
    "    unique_shows = df['program.name'].unique().tolist()\n",
    "    \n",
    "    # creating a tuple with each unique show and its closest matches with FuzzyWuzzy token sort ration method\n",
    "    match_tuple = [(x,) + i\n",
    "                   for x in unique_shows\n",
    "                   for i in process.extract(x,unique_shows, scorer=fuzz.token_sort_ratio)]\n",
    "\n",
    "    analysis_df = pd.DataFrame(columns=['program.name','matched.program', 'score'], data=match_tuple)\n",
    "    \n",
    "    return analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_show_df = get_matching_shows(full_df)\n",
    "\n",
    "# filter for shows that only match > 70\n",
    "matching_show_df = matching_show_df[(matching_show_df.score > 80) & (matching_show_df.score < 100)]\n",
    "matching_show_df.to_csv('../dataverse_files/raw_matching_shows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc14ba69",
   "metadata": {},
   "source": [
    "After exporting the matching program names with fuzzy wuzzy, manually went through the file and only kept one show to replace each program.  If a show listed was not to be changed then the entry was ommitted.  This was used as a lookup in the code below to do most of the heavy lifting of converting shows into the same string.  After that we still had some that had to be edited manaually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_show_df = pd.read_csv('../dataverse_files/show_lookup.csv')\n",
    "matching_show_df.reset_index(drop=True)\n",
    "matching_show_df.drop(['Unnamed: 0', 'score'],axis=1, inplace=True)\n",
    "matching_show_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8cb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.loc[full_df['program.name'].isin(matching_show_df['program.name']),['program.name']] = matching_show_df['matched.program']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['program.name'] = full_df['program.name'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1091be",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.drop(full_df[full_df['program.name'].isnull()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c374b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(full_df['program.name'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a371a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the shows that fuzzy wuzzy didn't catch, the list was small enough that doing it by \n",
    "full_df.loc[full_df['program.name']=='Ac 360 Degrees','program.name'] = 'Anderson Cooper 360 Degrees'\n",
    "full_df.loc[full_df['program.name']=='American Morning With Paula Zahn','program.name'] = 'American Morning'\n",
    "full_df.loc[full_df['program.name']=='Cnn American Morning With Paula Zahn','program.name'] = 'American Morning'\n",
    "full_df.loc[full_df['program.name']=='Cnn International Q&A;','program.name'] = 'Cnn International Q&A'\n",
    "full_df.loc[full_df['program.name']=='Cnn Late Edition With Wolf Blitzer','program.name'] = 'Cnn Late Edition'\n",
    "full_df.loc[full_df['program.name']=='Cnn News Night Aaron Brown','program.name'] = 'Cnn Newsnight With Aaron Brown'\n",
    "full_df.loc[full_df['program.name']=='Cnn Newsnight Aaron Brown','program.name'] = 'Cnn Newsnight With Aaron Brown'\n",
    "full_df.loc[full_df['program.name']=='Cnn Page One With Nick Charles','program.name'] = 'Cnn Page One'\n",
    "full_df.loc[full_df['program.name']=='Cnn Saturday Edition','program.name'] = 'Cnn Saturday'\n",
    "full_df.loc[full_df['program.name']=='Cnn Showdown On Iraq','program.name'] = 'Cnn Showdown: Iraq'\n",
    "full_df.loc[full_df['program.name']=='Cnn The Point With Greta Van Susteren','program.name'] = 'Cnn The Point'\n",
    "full_df.loc[full_df['program.name']=='Cnn The Spin Room Corrected Copy','program.name'] = 'Cnn The Spin Room'\n",
    "full_df.loc[full_df['program.name']==\"CNN'S AMANPOUR\",'program.name'] = 'Amanpour'\n",
    "full_df.loc[full_df['program.name']=='Cnn&Time;','program.name'] = 'CNN/Time'\n",
    "full_df.loc[full_df['program.name']=='Evans, Novak, Hunt & Shields','program.name'] = 'Cnn Evans, Novak, Hunt & Shields'\n",
    "full_df.loc[full_df['program.name']=='Hardball With Chris Matthews','program.name'] = 'Hardball'\n",
    "full_df.loc[full_df['program.name']==\"Hardball With Chris Matthews' Fortuesday\",'program.name'] = 'Hardball'\n",
    "full_df.loc[full_df['program.name']==\"Hardball With Chris Matthews' Forwednesday\",'program.name'] = 'Hardball'\n",
    "full_df.loc[full_df['program.name']=='Jane Velez-Mitchell','program.name'] = 'Issues With Jane Velez-Mitchell'\n",
    "full_df.loc[full_df['program.name']==\"Judy Woodruffs'S Inside Politics\",'program.name'] = \"Judy Woodruff'S Inside Politics\"\n",
    "full_df.loc[full_df['program.name']=='Melissa-Harris-Perry','program.name'] = 'The Melissa Harris-Perry Show'\n",
    "full_df.loc[full_df['program.name']=='Melissa Harris-Perry','program.name'] = 'The Melissa Harris-Perry Show'\n",
    "full_df.loc[full_df['program.name']=='Msnbc Hardball','program.name'] = 'Hardball'\n",
    "full_df.loc[full_df['program.name']=='Politicsnation','program.name'] = 'Politics Nation'\n",
    "full_df.loc[full_df['program.name']=='The Ed Show With Ed Schultz','program.name'] = 'The Ed Show'\n",
    "full_df.loc[full_df['program.name']=='The Ed Show Forthursday,July 19Th','program.name'] = 'The Ed Show'\n",
    "full_df.loc[full_df['program.name']==\"The Last Word With Lawrence O' Donnell\",'program.name'] = \"The Last Word With Lawrence O'Donnell\"\n",
    "full_df.loc[full_df['program.name']==\"The Last Word With Lawrence O'Donnell' Forthursday\",'program.name'] = \"The Last Word With Lawrence O'Donnell\"\n",
    "full_df.loc[full_df['program.name']==\"The Last Word With Lawrence O'Donnell' Fortuesday\",'program.name'] = \"The Last Word With Lawrence O'Donnell\"\n",
    "full_df.loc[full_df['program.name']==\"The Last Word With Lawrence O'Donnell' Fothursday\",'program.name'] = \"The Last Word With Lawrence O'Donnell\"\n",
    "full_df.loc[full_df['program.name']==\"The Last Word With Lawrence O'Donnell' Wednesday\",'program.name'] = \"The Last Word With Lawrence O'Donnell\"\n",
    "full_df.loc[full_df['program.name']=='The Point With Greta Van Susteren','program.name'] = 'The Point'\n",
    "full_df.loc[full_df['program.name']==\"The Rachel Maddow Show'Forã\\x82Â\\xa0 Monday\",'program.name'] = 'The Rachel Maddow Show'\n",
    "full_df.loc[full_df['program.name']=='World Beat','program.name'] = 'Worldbeat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b0d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# final cosmetic changes\n",
    "full_df['program.name'] = full_df['program.name'].str.replace('Cnn','CNN')\n",
    "full_df['program.name'] = full_df['program.name'].str.replace('Msnbc','MSNBC')\n",
    "full_df['program.name'] = full_df['program.name'].str.replace(\"'S\",\"'s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a9625",
   "metadata": {},
   "source": [
    "# Analysis Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af4a18",
   "metadata": {},
   "source": [
    "Filtering for shows that have had at least 100 transcripts, even though we split the long transcipts into mulitple lines if it was over 5000 words long this is a good enough estimate at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9889ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_soft_news_df = full_df[full_df.groupby(['program.name','channel.name'])['prob_soft_news_us'].transform('count') > 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9776c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the size of the original dataframe to the new filtered dataframe\n",
    "print (f'Original dataframe size: {full_df.shape}')\n",
    "print (f'Filtered dataframe size: {filt_soft_news_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_news_df_grp = filt_soft_news_df.groupby(['program.name','channel.name'])['prob_soft_news_us'].mean().reset_index()\n",
    "soft_news_df_grp = soft_news_df_grp.sort_values(['channel.name','program.name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use column names of df for the different parameters x, y, color, ...\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,soft_news_df_grp.shape[0]/3))\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sns.scatterplot(x=\"prob_soft_news_us\", y=\"program.name\", data=soft_news_df_grp,\n",
    "                      hue=\"channel.name\", ax=ax, size_norm=.2\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cad75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
