{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c2f396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Bashar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Bashar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from notnews import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cda36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '../dataverse_files/'\n",
    "PROCESSED_PATH = FILE_PATH + 'processed/'\n",
    "PREDICT_NEWS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc76b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(s, n):\n",
    "    pieces = str(s).split()\n",
    "    return (' '.join(pieces[i:i+n]) for i in range(0, len(pieces), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd6de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, column, num=500):\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        presplit = pattern.sub('', presplit)\n",
    "        w_generator = split_text(presplit, num)\n",
    "        for word in w_generator:\n",
    "            indexes.append(i)\n",
    "            new_values.append(word)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f306465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_soft_news_file(file, channel_name, col='text'):\n",
    "    print (file)\n",
    "    df = pd.read_csv( FILE_PATH + str(file), encoding = 'ISO-8859-1')\n",
    "    print (f'Processing: {FILE_PATH + str(file)} ....')\n",
    "    split_data = split_df(df, 'text')\n",
    "    print (f'Finished splitting {FILE_PATH + str(file)} into chunks')\n",
    "    soft_news_df = pred_soft_news_us(split_data, col=col)\n",
    "    print (f'Saving results for {FILE_PATH + str(file)}\\n\\n')\n",
    "    soft_news_df.to_csv('{}soft_news_{}'.format(PROCESSED_PATH, file))\n",
    "    os.rename(FILE_PATH+file, PROCESSED_PATH+file)\n",
    "    \n",
    "    return soft_news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85029408",
   "metadata": {},
   "source": [
    "# Predicting Soft News probability\n",
    "If PREDICT_NEWS = True then will run, this is very time consuming and should be run once\n",
    "After which, the files generated should be saved to disk and preserved for future analysis\n",
    "  as run time could take days depending on the number of records to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cca0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definining pattern of timestamps in transcripts to remove\n",
    "pattern = re.compile(r'\\[[^a-zA-Z]*\\]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076e000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe02098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataverse_files/cnn-1.csv\n",
      "Processing: ../dataverse_files/../dataverse_files/cnn-1.csv ....\n",
      "Finished splitting ../dataverse_files/../dataverse_files/cnn-1.csv into chunks\n"
     ]
    }
   ],
   "source": [
    "# ingesting CNN Files\n",
    "files = glob.glob(FILE_PATH + 'cnn*.csv')\n",
    "\n",
    "for file in files:\n",
    "    soft_news_df = predict_soft_news_file(file, 'CNN')\n",
    "    full_df = full_df.concat(soft_news_df, axis=0)\n",
    "    \n",
    "file = 'msnbc.csv'\n",
    "soft_news_df = predict_soft_news_file(file, 'NBC News')\n",
    "full_df = full_df.concat(soft_news_df, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddcab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
